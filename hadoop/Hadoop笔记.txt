
=======================================================================================================
切片流程
Input(读入数据集)-->InputFormat(切片)-->shuffle-->OutputFormat-->Output(输出结果集)

数据切片与MapTask并行度机制？
1、一个Job的Map阶段并行度是由客户端在提交Job时的切片数决定。
2、每一个Split切片分配一个MapTask并行实例处理。
3、默认情况下，切片大小=BlockSize。
4、切片时不考虑数据集整体，而是逐个针对每一个文件单独切片。

切片的规则（切片的在具体执行是依靠InputFormat这个类进行的）:
Math.max(minSize, Math.min(maxSize, blockSize));
切片的最小值，切片的最大值，块大小
取中间那个值

当文件的大小大于128Mb*1.1的时候，开始切片。
当文件的大小小于128Mb*1.1的时候，把该文件当成一个整体。

CombineTextInputFormat切片方式：先按照4Mb进行文件分块，之后把分成的块逐个累加，没当刚大于4mb的时候，切分为一片
小于4Mb为一块，大于4Mb的文件，小于4*2mb的文件，先切一个4mb的块，在将剩下的平均切成两块。

InputFormat      切片方法            kv方法
Text             FIF的切片方法        LineRecordReader
Text             FIF的切片方法        KeyValueLineRecordReader
NLine            自定义，n行一片       LineRecordReader
CombineText      自定义               CombineFIleRecordReader
FixedLength      FIF的切片方法         FixedLengthRecordReader
SequenceFile     FiF的切片方法         SequenceFileRecordReader

MapReduce的详细工作流程
1、待处理文本 /user/input
2、客户端submit()前，获取待处理的数据的信息，然后根据参数配置，形成一个任务分配的规划。
3、提交信息（Job.split、wc.jar、job.xml等）
4、计算MapTask的数量
5、默认TextInputFormat
6、逻辑运算
7、向环形缓冲区写入kv数据
8、分区、排序，利用归并排序进行全排序
9、溢出到文件（分区且区内有序）
10、Merge归并排序。

区内进行快排

MapTask = 分片数（所谓分区：指明数据应该去往哪个MapTask）
Reduce = 需求（可以自己指定，每个reduceTask对应一个分区文件）

shuffle机制:
1、map--写入kv数据到缓冲区；
    具体过程：先将数据写入到数据缓冲区（默认为100Mb），此时的数据已经被逻辑分区为（k，v，pId），
    再进行二次排序（先按照分区号排序，内部再按照key排序）
    当数据量大于缓冲区的时候，将数据溢写到磁盘，此时需要按照分区号进行物理上的分区溢写；
    combiner是为了减少io。
    数据落盘之前，假如开启了combiner，则将数据输入到combiner进行一次合并，再进行真正落盘；
    combiner为可选流程，主要按照分区进行进行归并排序，之后在按照分区进行合并，压缩之后写入到磁盘。

假设有n个mapTask,每个reduceTask都会处理所有mapTask相应分区的数据。

Reduce--输出文件，将数锯copy到内存缓冲区，内存不够则溢写到磁盘，最后进行归并排序合成整个文件，
文件特点：按照相同的key有序排列，分组之后出入到reduce方法中去

环形内存缓冲区一边存储kv，以边存储索引，达到80%后就开始溢写，当数据再来了的时候，在10%的位置开始写，将80%中的数据溢写到磁盘。
溢写的时候发生二次排序（快排），分区排序和key排序，该排序的方法发生在内存环形缓冲区中，排序的时候不交换数据，仅交换索引。



2、partition--sort--内存不够，溢出刷新缓冲区数据到磁盘，先进行分区，再进行快速排序；
3、combiner--按照分区进行归并排序，合并分区并排序；
4、得到分区输出结果；
copy--copy到内存中，内存不够则溢出数据到磁盘，对每个map来的数据进行归并排序--按照相同的key分组--交给reducer方法

Partitioner的分区号，必须从0开始。

！！！ reduce输入原理
分区：
分组:针对有序的分区数据
归并：打多个文件合并成一个文件





分区的意义：告诉某一条数据应该被哪个Task处理

Map到Reduce的过程经过强制性的全排序。
 
combiner作用：减少磁盘Map阶段的局部IO

排序和分組的關係不一樣，先排序后分組

假如分組規則和排序規則不一樣，排序規則要比分組規則的粒度更細


在同一個節點中，數據的傳遞不是按照對象傳遞的，是序列化之後再傳遞，反序列化后接受

整個MR過程的數據傳遞都需要經過序列化

=======================================================================================================
ReduceJoin思路如下：
1、join字段相同的数据进入同一组。
2、join的工作在reduce中完成。
因为reduce阶段有数据的汇总，所以reduce可以完成join。
而map适用于一张表十分小，一张表很大的场景，需要把小表完全的缓存中内存。

思考：在Reduce端处理过多的表，非常容器出现数据倾斜，怎么办？
在map端完成了join，则不在需要reduce，没有reduce则没有shuffle。没有shuffle就没有数据倾斜，处理速度就会很快。
数据经过shuffle后会重新进行数据分配，进而产生数据倾斜。




















